{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cddefd4-c108-4b67-8418-6c9fcb9924fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES REQUIRED\n",
    "import numpy as np \n",
    "import json\n",
    "import pickle\n",
    "import os \n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b65324-6831-4fdc-9725-d8844df8eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE TEXT : VIRAT KOHLI - WIKI\n",
    "text = \"Virat Kohli (born 5 November 1988)[a] is an Indian international cricketer who plays ODI cricket for the national team and is a former captain in all formats.[3] He is a right-handed batsman and occasional right-arm medium pace bowler. Considered one of the greatest all-format batsmen in the history of cricket, he is called the King, the Chase Master, and the Run Machine for his skills, records and ability to lead his team to victory.[4] Kohli is the highest run-scorer in the Indian Premier League, third in T20I, third in ODI, and third in international cricket.[5] He has the most ODI centuries and second-most centuries in international cricket, with a total of 82 centuries across all international formats of the game.[6] Kohli is also the most successful Test captain of India with back-to-back Test mace wins and most victories in his tenure.[7] He is the only batter to earn 900 rating points in all three formats.[8] Kohli was the captain of the 2008 U19 World Cup winning team and was a crucial member of the teams that won 2011 ODI World Cup, 2013 Champions Trophy, 2024 T20 World Cup, and 2025 Champions Trophy. He plays for Royal Challengers Bengaluru in the Indian Premier League and for Delhi in domestic cricket. In 2013, Kohli was ranked number one in the ODI batting rankings. In 2015, he achieved the same in T20I.[9] In 2018, he was ranked number one in Test, making him the only Indian to hold the number one spot in all three formats. He is the first player to score 20,000 runs in a decade. He was the Cricketer of the Decade for 2011 to 2020.[10] Kohli has won ten ICC Awards, making him the most awarded player in international cricket history. He won the ODI Player of the Year award four times in 2012, 2017, 2018, and 2023. He won the Cricketer of the Year award, on two occasions, in 2017 and 2018. In 2018, he became the first player to win all three major awards including Cricketer of the Year, ODI Player of the Year and Test Player of the Year in the same year. He was honored with the Spirit of Cricket Award in 2019 and given the Cricketer of the Decade and ODI Cricketer of the Decade in 2020. Kohli was named the Wisden Leading Cricketer in the World for three consecutive years. Kohli has the most Player of the Series and second most Player of the Match awards to his name in all three formats combined. He was honoured with the Arjuna Award in 2013, the Padma Shri in 2017, and India's highest sporting honour, the Khel Ratna Award, in 2018. Time included him on its 100 most influential people in the world list in 2018.After winning the 2024 T20 World Cup and winning the Player of the Match award in the final, Kohli announced his retirement from T20Is.[11] On 12 May 2025, aged 36, he announced his retirement from the Test format.[12] He is married to actress Anushka Sharma, and they have two children.[13]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3392b5-ddf6-4e76-b1f9-ed339db7379a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2858"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of characters\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf19060-c031-4c96-bdb0-a489b3c2ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each character in the input text to its corresponding byte (integer) using UTF-8 encoding\n",
    "# Example: \"hello\" -> [104, 101, 108, 108, 111]\n",
    "tokens = list(text.encode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c83842b-3d50-46a6-aafe-8a5b625d52df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 105, 114, 97, 116, 32, 75, 111, 104, 108, 105, 32, 40, 98, 111, 114, 110, 32, 53, 32, 78, 111, 118, 101, 109, 98, 101, 114, 32, 49, 57, 56, 56, 41, 91, 97, 93, 32, 105, 115, 32, 97, 110, 32, 73, 110, 100, 105, 97, 110, 32, 105, 110, 116, 101, 114, 110, 97, 116, 105, 111, 110, 97, 108, 32, 99, 114, 105, 99, 107, 101, 116, 101, 114, 32, 119, 104, 111, 32, 112, 108, 97, 121, 115, 32, 79, 68, 73, 32, 99, 114, 105, 99, 107, 101, 116, 32, 102, 111, 114, 32, 116, 104, 101, 32, 110, 97, 116, 105, 111, 110, 97, 108, 32, 116, 101, 97, 109, 32, 97, 110, 100, 32, 105, 115, 32, 97, 32, 102, 111, 114, 109, 101, 114, 32, 99, 97, 112, 116, 97, 105, 110, 32, 105, 110, 32, 97, 108, 108, 32, 102, 111, 114, 109, 97, 116, 115, 46, 91, 51, 93, 32, 72, 101, 32, 105, 115, 32, 97, 32, 114, 105, 103, 104, 116, 45, 104, 97, 110, 100, 101, 100, 32, 98, 97, 116, 115, 109, 97, 110, 32, 97, 110, 100, 32, 111, 99, 99, 97, 115, 105, 111, 110, 97, 108, 32, 114, 105, 103, 104, 116, 45, 97, 114, 109, 32, 109, 101, 100, 105, 117, 109, 32, 112, 97, 99, 101, 32, 98, 111, 119, 108, 101, 114, 46, 32, 67, 111, 110, 115, 105, 100, 101, 114, 101, 100, 32, 111, 110, 101, 32, 111, 102, 32, 116, 104, 101, 32, 103, 114, 101, 97, 116, 101, 115, 116, 32, 97, 108, 108, 45, 102, 111, 114, 109, 97, 116, 32, 98, 97, 116, 115, 109, 101, 110, 32, 105, 110, 32, 116, 104, 101, 32, 104, 105, 115, 116, 111, 114, 121, 32, 111, 102, 32, 99, 114, 105, 99, 107, 101, 116, 44, 32, 104, 101, 32, 105, 115, 32, 99, 97, 108, 108, 101, 100, 32, 116, 104, 101, 32, 75, 105, 110, 103, 44, 32, 116, 104, 101, 32, 67, 104, 97, 115, 101, 32, 77, 97, 115, 116, 101, 114, 44, 32, 97, 110, 100, 32, 116, 104, 101, 32, 82, 117, 110, 32, 77, 97, 99, 104, 105, 110, 101, 32, 102, 111, 114, 32, 104, 105, 115, 32, 115, 107, 105, 108, 108, 115, 44, 32, 114, 101, 99, 111, 114, 100, 115, 32, 97, 110, 100, 32, 97, 98, 105, 108, 105, 116, 121, 32, 116, 111, 32, 108, 101, 97, 100, 32, 104, 105, 115, 32, 116, 101, 97, 109, 32, 116, 111, 32, 118, 105, 99, 116, 111, 114, 121, 46, 91, 52, 93, 32, 75, 111, 104, 108, 105, 32, 105, 115, 32, 116, 104, 101, 32, 104, 105, 103, 104, 101, 115, 116, 32, 114, 117, 110, 45, 115, 99, 111, 114, 101, 114, 32, 105, 110, 32, 116, 104, 101, 32, 73, 110, 100, 105, 97, 110, 32, 80, 114, 101, 109, 105, 101, 114, 32, 76, 101, 97, 103, 117, 101, 44, 32, 116, 104, 105, 114, 100, 32, 105, 110, 32, 84, 50, 48, 73, 44, 32, 116, 104, 105, 114, 100, 32, 105, 110, 32, 79, 68, 73, 44, 32, 97, 110, 100, 32, 116, 104, 105, 114, 100, 32, 105, 110, 32, 105, 110, 116, 101, 114, 110, 97, 116, 105, 111, 110, 97, 108, 32, 99, 114, 105, 99, 107, 101, 116, 46, 91, 53, 93, 32, 72, 101, 32, 104, 97, 115, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 79, 68, 73, 32, 99, 101, 110, 116, 117, 114, 105, 101, 115, 32, 97, 110, 100, 32, 115, 101, 99, 111, 110, 100, 45, 109, 111, 115, 116, 32, 99, 101, 110, 116, 117, 114, 105, 101, 115, 32, 105, 110, 32, 105, 110, 116, 101, 114, 110, 97, 116, 105, 111, 110, 97, 108, 32, 99, 114, 105, 99, 107, 101, 116, 44, 32, 119, 105, 116, 104, 32, 97, 32, 116, 111, 116, 97, 108, 32, 111, 102, 32, 56, 50, 32, 99, 101, 110, 116, 117, 114, 105, 101, 115, 32, 97, 99, 114, 111, 115, 115, 32, 97, 108, 108, 32, 105, 110, 116, 101, 114, 110, 97, 116, 105, 111, 110, 97, 108, 32, 102, 111, 114, 109, 97, 116, 115, 32, 111, 102, 32, 116, 104, 101, 32, 103, 97, 109, 101, 46, 91, 54, 93, 32, 75, 111, 104, 108, 105, 32, 105, 115, 32, 97, 108, 115, 111, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 115, 117, 99, 99, 101, 115, 115, 102, 117, 108, 32, 84, 101, 115, 116, 32, 99, 97, 112, 116, 97, 105, 110, 32, 111, 102, 32, 73, 110, 100, 105, 97, 32, 119, 105, 116, 104, 32, 98, 97, 99, 107, 45, 116, 111, 45, 98, 97, 99, 107, 32, 84, 101, 115, 116, 32, 109, 97, 99, 101, 32, 119, 105, 110, 115, 32, 97, 110, 100, 32, 109, 111, 115, 116, 32, 118, 105, 99, 116, 111, 114, 105, 101, 115, 32, 105, 110, 32, 104, 105, 115, 32, 116, 101, 110, 117, 114, 101, 46, 91, 55, 93, 32, 72, 101, 32, 105, 115, 32, 116, 104, 101, 32, 111, 110, 108, 121, 32, 98, 97, 116, 116, 101, 114, 32, 116, 111, 32, 101, 97, 114, 110, 32, 57, 48, 48, 32, 114, 97, 116, 105, 110, 103, 32, 112, 111, 105, 110, 116, 115, 32, 105, 110, 32, 97, 108, 108, 32, 116, 104, 114, 101, 101, 32, 102, 111, 114, 109, 97, 116, 115, 46, 91, 56, 93, 32, 75, 111, 104, 108, 105, 32, 119, 97, 115, 32, 116, 104, 101, 32, 99, 97, 112, 116, 97, 105, 110, 32, 111, 102, 32, 116, 104, 101, 32, 50, 48, 48, 56, 32, 85, 49, 57, 32, 87, 111, 114, 108, 100, 32, 67, 117, 112, 32, 119, 105, 110, 110, 105, 110, 103, 32, 116, 101, 97, 109, 32, 97, 110, 100, 32, 119, 97, 115, 32, 97, 32, 99, 114, 117, 99, 105, 97, 108, 32, 109, 101, 109, 98, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 116, 101, 97, 109, 115, 32, 116, 104, 97, 116, 32, 119, 111, 110, 32, 50, 48, 49, 49, 32, 79, 68, 73, 32, 87, 111, 114, 108, 100, 32, 67, 117, 112, 44, 32, 50, 48, 49, 51, 32, 67, 104, 97, 109, 112, 105, 111, 110, 115, 32, 84, 114, 111, 112, 104, 121, 44, 32, 50, 48, 50, 52, 32, 84, 50, 48, 32, 87, 111, 114, 108, 100, 32, 67, 117, 112, 44, 32, 97, 110, 100, 32, 50, 48, 50, 53, 32, 67, 104, 97, 109, 112, 105, 111, 110, 115, 32, 84, 114, 111, 112, 104, 121, 46, 32, 72, 101, 32, 112, 108, 97, 121, 115, 32, 102, 111, 114, 32, 82, 111, 121, 97, 108, 32, 67, 104, 97, 108, 108, 101, 110, 103, 101, 114, 115, 32, 66, 101, 110, 103, 97, 108, 117, 114, 117, 32, 105, 110, 32, 116, 104, 101, 32, 73, 110, 100, 105, 97, 110, 32, 80, 114, 101, 109, 105, 101, 114, 32, 76, 101, 97, 103, 117, 101, 32, 97, 110, 100, 32, 102, 111, 114, 32, 68, 101, 108, 104, 105, 32, 105, 110, 32, 100, 111, 109, 101, 115, 116, 105, 99, 32, 99, 114, 105, 99, 107, 101, 116, 46, 32, 73, 110, 32, 50, 48, 49, 51, 44, 32, 75, 111, 104, 108, 105, 32, 119, 97, 115, 32, 114, 97, 110, 107, 101, 100, 32, 110, 117, 109, 98, 101, 114, 32, 111, 110, 101, 32, 105, 110, 32, 116, 104, 101, 32, 79, 68, 73, 32, 98, 97, 116, 116, 105, 110, 103, 32, 114, 97, 110, 107, 105, 110, 103, 115, 46, 32, 73, 110, 32, 50, 48, 49, 53, 44, 32, 104, 101, 32, 97, 99, 104, 105, 101, 118, 101, 100, 32, 116, 104, 101, 32, 115, 97, 109, 101, 32, 105, 110, 32, 84, 50, 48, 73, 46, 91, 57, 93, 32, 73, 110, 32, 50, 48, 49, 56, 44, 32, 104, 101, 32, 119, 97, 115, 32, 114, 97, 110, 107, 101, 100, 32, 110, 117, 109, 98, 101, 114, 32, 111, 110, 101, 32, 105, 110, 32, 84, 101, 115, 116, 44, 32, 109, 97, 107, 105, 110, 103, 32, 104, 105, 109, 32, 116, 104, 101, 32, 111, 110, 108, 121, 32, 73, 110, 100, 105, 97, 110, 32, 116, 111, 32, 104, 111, 108, 100, 32, 116, 104, 101, 32, 110, 117, 109, 98, 101, 114, 32, 111, 110, 101, 32, 115, 112, 111, 116, 32, 105, 110, 32, 97, 108, 108, 32, 116, 104, 114, 101, 101, 32, 102, 111, 114, 109, 97, 116, 115, 46, 32, 72, 101, 32, 105, 115, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 112, 108, 97, 121, 101, 114, 32, 116, 111, 32, 115, 99, 111, 114, 101, 32, 50, 48, 44, 48, 48, 48, 32, 114, 117, 110, 115, 32, 105, 110, 32, 97, 32, 100, 101, 99, 97, 100, 101, 46, 32, 72, 101, 32, 119, 97, 115, 32, 116, 104, 101, 32, 67, 114, 105, 99, 107, 101, 116, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 68, 101, 99, 97, 100, 101, 32, 102, 111, 114, 32, 50, 48, 49, 49, 32, 116, 111, 32, 50, 48, 50, 48, 46, 91, 49, 48, 93, 32, 75, 111, 104, 108, 105, 32, 104, 97, 115, 32, 119, 111, 110, 32, 116, 101, 110, 32, 73, 67, 67, 32, 65, 119, 97, 114, 100, 115, 44, 32, 109, 97, 107, 105, 110, 103, 32, 104, 105, 109, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 97, 119, 97, 114, 100, 101, 100, 32, 112, 108, 97, 121, 101, 114, 32, 105, 110, 32, 105, 110, 116, 101, 114, 110, 97, 116, 105, 111, 110, 97, 108, 32, 99, 114, 105, 99, 107, 101, 116, 32, 104, 105, 115, 116, 111, 114, 121, 46, 32, 72, 101, 32, 119, 111, 110, 32, 116, 104, 101, 32, 79, 68, 73, 32, 80, 108, 97, 121, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 89, 101, 97, 114, 32, 97, 119, 97, 114, 100, 32, 102, 111, 117, 114, 32, 116, 105, 109, 101, 115, 32, 105, 110, 32, 50, 48, 49, 50, 44, 32, 50, 48, 49, 55, 44, 32, 50, 48, 49, 56, 44, 32, 97, 110, 100, 32, 50, 48, 50, 51, 46, 32, 72, 101, 32, 119, 111, 110, 32, 116, 104, 101, 32, 67, 114, 105, 99, 107, 101, 116, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 89, 101, 97, 114, 32, 97, 119, 97, 114, 100, 44, 32, 111, 110, 32, 116, 119, 111, 32, 111, 99, 99, 97, 115, 105, 111, 110, 115, 44, 32, 105, 110, 32, 50, 48, 49, 55, 32, 97, 110, 100, 32, 50, 48, 49, 56, 46, 32, 73, 110, 32, 50, 48, 49, 56, 44, 32, 104, 101, 32, 98, 101, 99, 97, 109, 101, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 112, 108, 97, 121, 101, 114, 32, 116, 111, 32, 119, 105, 110, 32, 97, 108, 108, 32, 116, 104, 114, 101, 101, 32, 109, 97, 106, 111, 114, 32, 97, 119, 97, 114, 100, 115, 32, 105, 110, 99, 108, 117, 100, 105, 110, 103, 32, 67, 114, 105, 99, 107, 101, 116, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 89, 101, 97, 114, 44, 32, 79, 68, 73, 32, 80, 108, 97, 121, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 89, 101, 97, 114, 32, 97, 110, 100, 32, 84, 101, 115, 116, 32, 80, 108, 97, 121, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 89, 101, 97, 114, 32, 105, 110, 32, 116, 104, 101, 32, 115, 97, 109, 101, 32, 121, 101, 97, 114, 46, 32, 72, 101, 32, 119, 97, 115, 32, 104, 111, 110, 111, 114, 101, 100, 32, 119, 105, 116, 104, 32, 116, 104, 101, 32, 83, 112, 105, 114, 105, 116, 32, 111, 102, 32, 67, 114, 105, 99, 107, 101, 116, 32, 65, 119, 97, 114, 100, 32, 105, 110, 32, 50, 48, 49, 57, 32, 97, 110, 100, 32, 103, 105, 118, 101, 110, 32, 116, 104, 101, 32, 67, 114, 105, 99, 107, 101, 116, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 68, 101, 99, 97, 100, 101, 32, 97, 110, 100, 32, 79, 68, 73, 32, 67, 114, 105, 99, 107, 101, 116, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 68, 101, 99, 97, 100, 101, 32, 105, 110, 32, 50, 48, 50, 48, 46, 32, 75, 111, 104, 108, 105, 32, 119, 97, 115, 32, 110, 97, 109, 101, 100, 32, 116, 104, 101, 32, 87, 105, 115, 100, 101, 110, 32, 76, 101, 97, 100, 105, 110, 103, 32, 67, 114, 105, 99, 107, 101, 116, 101, 114, 32, 105, 110, 32, 116, 104, 101, 32, 87, 111, 114, 108, 100, 32, 102, 111, 114, 32, 116, 104, 114, 101, 101, 32, 99, 111, 110, 115, 101, 99, 117, 116, 105, 118, 101, 32, 121, 101, 97, 114, 115, 46, 32, 75, 111, 104, 108, 105, 32, 104, 97, 115, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 80, 108, 97, 121, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 83, 101, 114, 105, 101, 115, 32, 97, 110, 100, 32, 115, 101, 99, 111, 110, 100, 32, 109, 111, 115, 116, 32, 80, 108, 97, 121, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 77, 97, 116, 99, 104, 32, 97, 119, 97, 114, 100, 115, 32, 116, 111, 32, 104, 105, 115, 32, 110, 97, 109, 101, 32, 105, 110, 32, 97, 108, 108, 32, 116, 104, 114, 101, 101, 32, 102, 111, 114, 109, 97, 116, 115, 32, 99, 111, 109, 98, 105, 110, 101, 100, 46, 32, 72, 101, 32, 119, 97, 115, 32, 104, 111, 110, 111, 117, 114, 101, 100, 32, 119, 105, 116, 104, 32, 116, 104, 101, 32, 65, 114, 106, 117, 110, 97, 32, 65, 119, 97, 114, 100, 32, 105, 110, 32, 50, 48, 49, 51, 44, 32, 116, 104, 101, 32, 80, 97, 100, 109, 97, 32, 83, 104, 114, 105, 32, 105, 110, 32, 50, 48, 49, 55, 44, 32, 97, 110, 100, 32, 73, 110, 100, 105, 97, 39, 115, 32, 104, 105, 103, 104, 101, 115, 116, 32, 115, 112, 111, 114, 116, 105, 110, 103, 32, 104, 111, 110, 111, 117, 114, 44, 32, 116, 104, 101, 32, 75, 104, 101, 108, 32, 82, 97, 116, 110, 97, 32, 65, 119, 97, 114, 100, 44, 32, 105, 110, 32, 50, 48, 49, 56, 46, 32, 84, 105, 109, 101, 32, 105, 110, 99, 108, 117, 100, 101, 100, 32, 104, 105, 109, 32, 111, 110, 32, 105, 116, 115, 32, 49, 48, 48, 32, 109, 111, 115, 116, 32, 105, 110, 102, 108, 117, 101, 110, 116, 105, 97, 108, 32, 112, 101, 111, 112, 108, 101, 32, 105, 110, 32, 116, 104, 101, 32, 119, 111, 114, 108, 100, 32, 108, 105, 115, 116, 32, 105, 110, 32, 50, 48, 49, 56, 46, 65, 102, 116, 101, 114, 32, 119, 105, 110, 110, 105, 110, 103, 32, 116, 104, 101, 32, 50, 48, 50, 52, 32, 84, 50, 48, 32, 87, 111, 114, 108, 100, 32, 67, 117, 112, 32, 97, 110, 100, 32, 119, 105, 110, 110, 105, 110, 103, 32, 116, 104, 101, 32, 80, 108, 97, 121, 101, 114, 32, 111, 102, 32, 116, 104, 101, 32, 77, 97, 116, 99, 104, 32, 97, 119, 97, 114, 100, 32, 105, 110, 32, 116, 104, 101, 32, 102, 105, 110, 97, 108, 44, 32, 75, 111, 104, 108, 105, 32, 97, 110, 110, 111, 117, 110, 99, 101, 100, 32, 104, 105, 115, 32, 114, 101, 116, 105, 114, 101, 109, 101, 110, 116, 32, 102, 114, 111, 109, 32, 84, 50, 48, 73, 115, 46, 91, 49, 49, 93, 32, 79, 110, 32, 49, 50, 32, 77, 97, 121, 32, 50, 48, 50, 53, 44, 32, 97, 103, 101, 100, 32, 51, 54, 44, 32, 104, 101, 32, 97, 110, 110, 111, 117, 110, 99, 101, 100, 32, 104, 105, 115, 32, 114, 101, 116, 105, 114, 101, 109, 101, 110, 116, 32, 102, 114, 111, 109, 32, 116, 104, 101, 32, 84, 101, 115, 116, 32, 102, 111, 114, 109, 97, 116, 46, 91, 49, 50, 93, 32, 72, 101, 32, 105, 115, 32, 109, 97, 114, 114, 105, 101, 100, 32, 116, 111, 32, 97, 99, 116, 114, 101, 115, 115, 32, 65, 110, 117, 115, 104, 107, 97, 32, 83, 104, 97, 114, 109, 97, 44, 32, 97, 110, 100, 32, 116, 104, 101, 121, 32, 104, 97, 118, 101, 32, 116, 119, 111, 32, 99, 104, 105, 108, 100, 114, 101, 110, 46, 91, 49, 51, 93]\n"
     ]
    }
   ],
   "source": [
    "# Print the list of UTF-8 encoded byte values (integers)\n",
    "# Helps visualize how the original text is represented at the byte level\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2211369-c4c1-438e-a1fc-a643440ac356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency of all adjacent token pairs in the input list.\n",
    "# This is the core step in BPE to identify which pair of tokens to merge.\n",
    "\n",
    "def get_stats(tokens): \n",
    "    freq = {}\n",
    "    for i in range(len(tokens) - 1): \n",
    "        pair = tokens[i], tokens[i + 1]  # Create a pair from each adjacent token\n",
    "        freq[pair] = freq.get(pair, 0) + 1  # Count how often each pair appears\n",
    "    return freq  # Return a dictionary: pair -> frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25abacd6-3cf5-4e69-91b5-68a6f40b574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the frequency of all adjacent byte pairs in the initial token list\n",
    "# This will be used to determine which pair should be merged first in the BPE process\n",
    "vocab = get_stats(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03efada4-776f-40cf-9140-2baa4f51f038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of unique adjacent token pairs in the current vocabulary\n",
    "# This gives an idea of how many distinct mergable token pairs exist\n",
    "len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17b6c5d-be59-4e40-be83-055b30bf4b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(86, 105): 1, (105, 114): 9, (114, 97): 5, (97, 116): 24, (116, 32): 28, (32, 75): 11, (75, 111): 9, (111, 104): 9, (104, 108): 9, (108, 105): 11, (105, 32): 11, (32, 40): 1, (40, 98): 1, (98, 111): 2, (111, 114): 31, (114, 110): 7, (110, 32): 58, (32, 53): 1, (53, 32): 2, (32, 78): 1, (78, 111): 1, (111, 118): 1, (118, 101): 5, (101, 109): 6, (109, 98): 6, (98, 101): 6, (101, 114): 37, (114, 32): 39, (32, 49): 3, (49, 57): 3, (57, 56): 1, (56, 56): 1, (56, 41): 1, (41, 91): 1, (91, 97): 1, (97, 93): 1, (93, 32): 11, (32, 105): 48, (105, 115): 19, (115, 32): 50, (32, 97): 46, (97, 110): 31, (32, 73): 11, (73, 110): 10, (110, 100): 28, (100, 105): 9, (105, 97): 8, (105, 110): 62, (110, 116): 12, (116, 101): 22, (110, 97): 18, (116, 105): 15, (105, 111): 10, (111, 110): 29, (97, 108): 23, (108, 32): 19, (32, 99): 18, (99, 114): 9, (114, 105): 24, (105, 99): 17, (99, 107): 16, (107, 101): 16, (101, 116): 16, (32, 119): 23, (119, 104): 1, (104, 111): 5, (111, 32): 13, (32, 112): 8, (112, 108): 6, (108, 97): 11, (97, 121): 12, (121, 115): 2, (32, 79): 9, (79, 68): 8, (68, 73): 8, (73, 32): 7, (32, 102): 19, (102, 111): 15, (32, 116): 80, (116, 104): 65, (104, 101): 60, (101, 32): 93, (32, 110): 6, (101, 97): 17, (97, 109): 12, (109, 32): 10, (100, 32): 50, (97, 32): 10, (114, 109): 10, (109, 101): 15, (99, 97): 11, (97, 112): 3, (112, 116): 3, (116, 97): 4, (97, 105): 3, (108, 108): 10, (109, 97): 15, (116, 115): 9, (115, 46): 6, (46, 91): 11, (91, 51): 1, (51, 93): 2, (32, 72): 11, (72, 101): 11, (32, 114): 11, (105, 103): 4, (103, 104): 4, (104, 116): 2, (116, 45): 2, (45, 104): 1, (104, 97): 11, (100, 101): 10, (101, 100): 17, (32, 98): 7, (98, 97): 6, (115, 109): 2, (32, 111): 29, (111, 99): 2, (99, 99): 3, (97, 115): 15, (115, 105): 3, (45, 97): 1, (97, 114): 21, (32, 109): 14, (105, 117): 1, (117, 109): 4, (112, 97): 1, (97, 99): 8, (99, 101): 8, (111, 119): 1, (119, 108): 1, (108, 101): 5, (114, 46): 2, (46, 32): 14, (32, 67): 16, (67, 111): 1, (110, 115): 7, (105, 100): 1, (114, 101): 21, (110, 101): 6, (111, 102): 19, (102, 32): 19, (32, 103): 3, (103, 114): 1, (101, 115): 17, (115, 116): 23, (108, 45): 1, (45, 102): 1, (101, 110): 14, (32, 104): 26, (104, 105): 20, (116, 111): 15, (114, 121): 3, (121, 32): 6, (116, 44): 3, (44, 32): 31, (75, 105): 1, (110, 103): 14, (103, 44): 1, (67, 104): 4, (115, 101): 4, (32, 77): 5, (77, 97): 5, (114, 44): 3, (32, 82): 3, (82, 117): 1, (117, 110): 6, (99, 104): 5, (32, 115): 9, (115, 107): 1, (107, 105): 4, (105, 108): 3, (108, 115): 2, (115, 44): 3, (101, 99): 9, (99, 111): 7, (114, 100): 14, (100, 115): 4, (97, 98): 1, (98, 105): 2, (105, 116): 7, (116, 121): 1, (32, 108): 2, (97, 100): 7, (32, 118): 2, (118, 105): 2, (99, 116): 3, (121, 46): 3, (91, 52): 1, (52, 93): 1, (114, 117): 4, (110, 45): 1, (45, 115): 1, (115, 99): 2, (32, 80): 9, (80, 114): 2, (109, 105): 2, (105, 101): 9, (32, 76): 3, (76, 101): 3, (97, 103): 3, (103, 117): 2, (117, 101): 3, (101, 44): 1, (32, 84): 13, (84, 50): 5, (50, 48): 33, (48, 73): 3, (73, 44): 2, (116, 46): 3, (91, 53): 1, (53, 93): 1, (109, 111): 8, (111, 115): 9, (116, 117): 3, (117, 114): 8, (100, 45): 1, (45, 109): 1, (119, 105): 9, (104, 32): 6, (111, 116): 2, (32, 56): 1, (56, 50): 1, (50, 32): 2, (114, 111): 5, (115, 115): 3, (103, 97): 2, (101, 46): 3, (91, 54): 1, (54, 93): 1, (115, 111): 1, (115, 117): 1, (117, 99): 2, (115, 102): 1, (102, 117): 1, (117, 108): 1, (84, 101): 5, (107, 45): 1, (45, 116): 1, (111, 45): 1, (45, 98): 1, (107, 32): 1, (110, 117): 5, (91, 55): 1, (55, 93): 1, (110, 108): 2, (108, 121): 2, (116, 116): 2, (32, 101): 1, (32, 57): 1, (57, 48): 1, (48, 48): 5, (48, 32): 5, (103, 32): 10, (112, 111): 3, (111, 105): 1, (104, 114): 6, (101, 101): 5, (91, 56): 1, (56, 93): 1, (119, 97): 18, (32, 50): 26, (48, 56): 1, (56, 32): 1, (32, 85): 1, (85, 49): 1, (57, 32): 2, (32, 87): 6, (87, 111): 5, (114, 108): 6, (108, 100): 8, (67, 117): 4, (117, 112): 4, (112, 32): 2, (110, 110): 5, (110, 105): 3, (99, 105): 1, (109, 115): 1, (119, 111): 7, (48, 49): 17, (49, 49): 3, (49, 32): 2, (112, 44): 2, (49, 51): 4, (51, 32): 1, (109, 112): 2, (112, 105): 3, (84, 114): 2, (111, 112): 3, (112, 104): 2, (104, 121): 2, (121, 44): 1, (48, 50): 7, (50, 52): 2, (52, 32): 2, (50, 53): 2, (82, 111): 1, (111, 121): 1, (121, 97): 1, (103, 101): 2, (114, 115): 4, (32, 66): 1, (66, 101): 1, (108, 117): 4, (117, 32): 1, (32, 68): 4, (68, 101): 4, (101, 108): 2, (108, 104): 1, (32, 100): 2, (100, 111): 1, (111, 109): 4, (99, 32): 1, (51, 44): 2, (110, 107): 3, (103, 115): 1, (49, 53): 1, (53, 44): 2, (101, 118): 1, (115, 97): 2, (73, 46): 1, (91, 57): 1, (57, 93): 1, (49, 56): 6, (56, 44): 3, (97, 107): 2, (105, 109): 5, (111, 108): 1, (115, 112): 2, (102, 105): 3, (121, 101): 11, (48, 44): 1, (44, 48): 1, (67, 114): 7, (48, 46): 2, (91, 49): 4, (49, 48): 2, (48, 93): 1, (73, 67): 1, (67, 67): 1, (67, 32): 1, (32, 65): 6, (65, 119): 4, (97, 119): 6, (80, 108): 6, (32, 89): 5, (89, 101): 5, (111, 117): 5, (49, 50): 3, (50, 44): 1, (49, 55): 3, (55, 44): 2, (50, 51): 1, (51, 46): 1, (100, 44): 2, (116, 119): 2, (55, 32): 1, (56, 46): 3, (97, 106): 1, (106, 111): 1, (110, 99): 4, (99, 108): 2, (117, 100): 2, (32, 121): 2, (110, 111): 5, (32, 83): 4, (83, 112): 1, (103, 105): 1, (105, 118): 2, (87, 105): 1, (115, 100): 1, (99, 117): 1, (117, 116): 1, (83, 101): 1, (116, 99): 2, (100, 46): 1, (65, 114): 1, (114, 106): 1, (106, 117): 1, (80, 97): 1, (100, 109): 1, (83, 104): 2, (97, 39): 1, (39, 115): 1, (114, 116): 1, (75, 104): 1, (82, 97): 1, (116, 110): 1, (84, 105): 1, (110, 102): 1, (102, 108): 1, (112, 101): 1, (101, 111): 1, (46, 65): 1, (65, 102): 1, (102, 116): 1, (108, 44): 1, (102, 114): 2, (73, 115): 1, (49, 93): 1, (79, 110): 1, (32, 51): 1, (51, 54): 1, (54, 44): 1, (50, 93): 1, (114, 114): 1, (116, 114): 1, (65, 110): 1, (117, 115): 1, (115, 104): 1, (104, 107): 1, (107, 97): 1, (97, 44): 1, (101, 121): 1, (97, 118): 1, (100, 114): 1, (110, 46): 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899e34d9-ee26-431b-8227-61c8326c77d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most frequent token pair to merge next:\n",
    "# 1. Convert the vocab dict to a list of tuples (frequency, pair)\n",
    "# 2. Sort the list in descending order of frequency\n",
    "# 3. Take the first element (most frequent), and extract the pair part\n",
    "\n",
    "freq_pair = max(sorted([(v, k) for k, v in vocab.items()], reverse=True))[1]\n",
    "freq_pair  # Display the most frequent pair to be merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcaae175-7fba-4b4e-b110-2c38a2fee0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all occurrences of the specified pair in the token list with a new token ID.\n",
    "\n",
    "def merge(tokens, pair, idx): \n",
    "    new_tokens = []  # Holds the updated tokens after merging\n",
    "    i = 0\n",
    "    while i < len(tokens): \n",
    "        # If the current and next token match the target pair\n",
    "        if i < len(tokens) - 1 and (tokens[i], tokens[i + 1]) == pair:\n",
    "            new_tokens.append(idx)  # Replace the pair with the new token ID\n",
    "            i += 2  # Skip the next token since it's part of the pair\n",
    "        else:\n",
    "            new_tokens.append(tokens[i])  # Keep the current token\n",
    "            i += 1\n",
    "    return new_tokens  # Return the updated token list after the merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b936fb1-03a8-44cd-9fe0-05ff237ed126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the merge function with a sample input:\n",
    "# Attempting to merge the pair (77, 9) by replacing it with token ID 89\n",
    "# Since the pair (77, 9) does NOT exist in the list, the output will be the same as the input\n",
    "\n",
    "merge([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], (77, 9), 89)\n",
    "# Output: [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 89, 9, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This time, the pair (7, 8) exists in the list at position 6 and 7.\n",
    "# It will be replaced by the token ID 89.\n",
    "# So, [7, 8] will be replaced with [89], and the rest of the list remains unchanged.\n",
    "\n",
    "merge([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], (7, 8), 89)\n",
    "# Output: [1, 2, 3, 4, 5, 6, 89, 9, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e644af4e-82a4-455b-b85a-69fefef72550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Byte Pair Encoding (BPE) on the input token list to learn merge rules.\n",
    "\n",
    "def bpe(vocab_size, original_tokens): \n",
    "    tokens = list(original_tokens)  # Copy the input tokens to avoid modifying original\n",
    "\n",
    "    # BPE requires vocab_size > 256 (first 256 are reserved for byte-level encoding)\n",
    "    # Also skip if not enough data for meaningful merging\n",
    "    if vocab_size <= 256 or vocab_size > len(tokens):\n",
    "        return tokens, None\n",
    "\n",
    "    idx = 256  # Start assigning new token IDs from 256\n",
    "    merge_dict = {}  # To store merge rules: (pair) â†’ new token ID\n",
    "    n_merges = vocab_size - 256  # Number of merges required to reach target vocab size\n",
    "\n",
    "    for _ in range(n_merges):\n",
    "        vocab = get_stats(tokens)  # Get frequency of token pairs\n",
    "        # Select most frequent token pair to merge\n",
    "        freq_pair = max(sorted([(v, k) for k, v in vocab.items()], reverse=True))[1]\n",
    "        merge_dict[freq_pair] = idx  # Store merge rule\n",
    "        tokens = merge(tokens, freq_pair, idx)  # Apply the merge\n",
    "        idx += 1  # Increment token ID for next merge\n",
    "\n",
    "    # Return the final merge dictionary, the last pair frequencies, and final token sequence\n",
    "    return merge_dict, vocab, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "175f9b6d-9f05-4488-a502-a94d364cf90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression achieved with 264 vocab size: X1.19\n"
     ]
    }
   ],
   "source": [
    "# Set the desired vocabulary size (must be > 256 to allow merges)\n",
    "# Why > 256? â†’ The first 256 token IDs are reserved for all possible single-byte UTF-8 values (0â€“255).\n",
    "# Any BPE merges start assigning new token IDs from 256 onward.\n",
    "desired_vocab_size = 264\n",
    "\n",
    "# Run the BPE algorithm to get the merge rules, final vocab stats, and compressed tokens\n",
    "merge_dict, vocab_dict, bpe_tokens = bpe(desired_vocab_size, tokens)\n",
    "\n",
    "# Calculate compression ratio: original token count / BPE token count\n",
    "compression = len(tokens) / len(bpe_tokens)\n",
    "\n",
    "# Print how much compression was achieved after BPE tokenization\n",
    "print(f\"Compression achieved with {desired_vocab_size} vocab size: X{np.round(compression, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8da33ed9-2372-43f0-91d9-67e4dc03f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression achieved with 512 vocab size: X3.17\n"
     ]
    }
   ],
   "source": [
    "# Increase the desired vocabulary size to allow more merges\n",
    "# With vocab_size = 512, the BPE algorithm can perform up to 512 - 256 = 256 merges\n",
    "# More merges â†’ fewer tokens â†’ higher compression (up to a limit)\n",
    "\n",
    "desired_vocab_size = 512\n",
    "\n",
    "# Run BPE with the new vocab size\n",
    "merge_dict, vocab_dict, bpe_tokens = bpe(desired_vocab_size, tokens)\n",
    "\n",
    "# Calculate how much the token count was reduced due to merging\n",
    "compression = len(tokens) / len(bpe_tokens)\n",
    "\n",
    "# Report the achieved compression ratio\n",
    "print(f\"Compression achieved with {desired_vocab_size} vocab size: X{np.round(compression, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9870b241-94bc-442c-84ff-9cedc0dfa694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(101, 32): 256,\n",
       " (32, 116): 257,\n",
       " (105, 110): 258,\n",
       " (257, 104): 259,\n",
       " (259, 256): 260,\n",
       " (100, 32): 261,\n",
       " (32, 97): 262,\n",
       " (101, 114): 263,\n",
       " (50, 48): 264,\n",
       " (111, 114): 265,\n",
       " (111, 110): 266,\n",
       " (115, 32): 267,\n",
       " (116, 32): 268,\n",
       " (263, 32): 269,\n",
       " (114, 105): 270,\n",
       " (97, 116): 271,\n",
       " (97, 114): 272,\n",
       " (258, 32): 273,\n",
       " (262, 110): 274,\n",
       " (111, 102): 275,\n",
       " (44, 32): 276,\n",
       " (264, 49): 277,\n",
       " (114, 101): 278,\n",
       " (115, 268): 279,\n",
       " (107, 101): 280,\n",
       " (104, 105): 281,\n",
       " (275, 260): 282,\n",
       " (97, 108): 283,\n",
       " (274, 261): 284,\n",
       " (270, 99): 285,\n",
       " (285, 280): 286,\n",
       " (110, 32): 287,\n",
       " (102, 265): 288,\n",
       " (46, 32): 289,\n",
       " (269, 282): 290,\n",
       " (258, 103): 291,\n",
       " (97, 121): 292,\n",
       " (97, 109): 293,\n",
       " (286, 116): 294,\n",
       " (111, 32): 295,\n",
       " (108, 292): 296,\n",
       " (108, 105): 297,\n",
       " (93, 32): 298,\n",
       " (72, 256): 299,\n",
       " (46, 91): 300,\n",
       " (283, 32): 301,\n",
       " (119, 272): 302,\n",
       " (105, 266): 303,\n",
       " (101, 110): 304,\n",
       " (111, 104): 305,\n",
       " (305, 297): 306,\n",
       " (99, 97): 307,\n",
       " (97, 110): 308,\n",
       " (75, 306): 309,\n",
       " (309, 32): 310,\n",
       " (288, 109): 311,\n",
       " (262, 108): 312,\n",
       " (258, 260): 313,\n",
       " (257, 295): 314,\n",
       " (119, 97): 315,\n",
       " (109, 111): 316,\n",
       " (105, 115): 317,\n",
       " (101, 272): 318,\n",
       " (101, 261): 319,\n",
       " (79, 68): 320,\n",
       " (320, 73): 321,\n",
       " (321, 32): 322,\n",
       " (316, 279): 323,\n",
       " (312, 108): 324,\n",
       " (291, 32): 325,\n",
       " (289, 299): 326,\n",
       " (273, 277): 327,\n",
       " (116, 263): 328,\n",
       " (101, 115): 329,\n",
       " (100, 105): 330,\n",
       " (311, 271): 331,\n",
       " (303, 301): 332,\n",
       " (302, 100): 333,\n",
       " (296, 290): 334,\n",
       " (265, 108): 335,\n",
       " (335, 261): 336,\n",
       " (110, 330): 337,\n",
       " (110, 271): 338,\n",
       " (109, 98): 339,\n",
       " (109, 97): 340,\n",
       " (105, 114): 341,\n",
       " (104, 256): 342,\n",
       " (101, 279): 343,\n",
       " (80, 334): 344,\n",
       " (73, 337): 345,\n",
       " (67, 294): 346,\n",
       " (346, 290): 347,\n",
       " (345, 97): 348,\n",
       " (338, 332): 349,\n",
       " (328, 349): 350,\n",
       " (315, 267): 351,\n",
       " (278, 256): 352,\n",
       " (276, 342): 353,\n",
       " (264, 50): 354,\n",
       " (259, 352): 355,\n",
       " (258, 350): 356,\n",
       " (258, 324): 357,\n",
       " (117, 110): 358,\n",
       " (116, 105): 359,\n",
       " (114, 111): 360,\n",
       " (112, 296): 361,\n",
       " (105, 116): 362,\n",
       " (104, 97): 363,\n",
       " (101, 100): 364,\n",
       " (99, 294): 365,\n",
       " (97, 99): 366,\n",
       " (89, 318): 367,\n",
       " (87, 336): 368,\n",
       " (84, 264): 369,\n",
       " (368, 67): 370,\n",
       " (370, 117): 371,\n",
       " (371, 112): 372,\n",
       " (362, 104): 373,\n",
       " (357, 355): 374,\n",
       " (339, 269): 375,\n",
       " (307, 100): 376,\n",
       " (302, 261): 377,\n",
       " (300, 49): 378,\n",
       " (298, 310): 379,\n",
       " (298, 299): 380,\n",
       " (293, 256): 381,\n",
       " (288, 32): 382,\n",
       " (287, 277): 383,\n",
       " (281, 267): 384,\n",
       " (281, 115): 385,\n",
       " (278, 109): 386,\n",
       " (275, 32): 387,\n",
       " (266, 256): 388,\n",
       " (262, 333): 389,\n",
       " (262, 32): 390,\n",
       " (257, 101): 391,\n",
       " (121, 32): 392,\n",
       " (119, 373): 393,\n",
       " (119, 266): 394,\n",
       " (119, 258): 395,\n",
       " (116, 265): 396,\n",
       " (115, 260): 397,\n",
       " (110, 117): 398,\n",
       " (109, 101): 399,\n",
       " (109, 32): 400,\n",
       " (103, 104): 401,\n",
       " (101, 376): 402,\n",
       " (101, 99): 403,\n",
       " (101, 97): 404,\n",
       " (98, 271): 405,\n",
       " (84, 343): 406,\n",
       " (73, 383): 407,\n",
       " (48, 48): 408,\n",
       " (402, 256): 409,\n",
       " (398, 375): 410,\n",
       " (410, 388): 411,\n",
       " (395, 110): 412,\n",
       " (412, 291): 413,\n",
       " (391, 293): 414,\n",
       " (374, 331): 415,\n",
       " (369, 73): 416,\n",
       " (364, 260): 417,\n",
       " (356, 365): 418,\n",
       " (348, 287): 419,\n",
       " (347, 68): 420,\n",
       " (420, 409): 421,\n",
       " (344, 367): 422,\n",
       " (341, 261): 423,\n",
       " (423, 273): 424,\n",
       " (317, 260): 425,\n",
       " (307, 112): 426,\n",
       " (426, 116): 427,\n",
       " (427, 97): 428,\n",
       " (428, 273): 429,\n",
       " (304, 116): 430,\n",
       " (430, 117): 431,\n",
       " (431, 270): 432,\n",
       " (289, 407): 433,\n",
       " (286, 268): 434,\n",
       " (276, 277): 435,\n",
       " (274, 100): 436,\n",
       " (259, 424): 437,\n",
       " (117, 114): 438,\n",
       " (115, 403): 439,\n",
       " (115, 276): 440,\n",
       " (114, 308): 441,\n",
       " (109, 260): 442,\n",
       " (108, 117): 443,\n",
       " (104, 266): 444,\n",
       " (99, 432): 445,\n",
       " (99, 265): 446,\n",
       " (97, 268): 447,\n",
       " (97, 32): 448,\n",
       " (76, 404): 449,\n",
       " (67, 104): 450,\n",
       " (44, 436): 451,\n",
       " (44, 284): 452,\n",
       " (44, 260): 453,\n",
       " (32, 372): 454,\n",
       " (452, 354): 455,\n",
       " (450, 293): 456,\n",
       " (456, 112): 457,\n",
       " (457, 303): 458,\n",
       " (458, 267): 459,\n",
       " (459, 84): 460,\n",
       " (460, 360): 461,\n",
       " (461, 112): 462,\n",
       " (462, 104): 463,\n",
       " (463, 121): 464,\n",
       " (449, 103): 465,\n",
       " (465, 117): 466,\n",
       " (448, 65): 467,\n",
       " (445, 329): 468,\n",
       " (444, 111): 469,\n",
       " (443, 100): 470,\n",
       " (441, 280): 471,\n",
       " (471, 261): 472,\n",
       " (472, 411): 473,\n",
       " (439, 266): 474,\n",
       " (419, 80): 475,\n",
       " (475, 386): 476,\n",
       " (476, 105): 477,\n",
       " (477, 269): 478,\n",
       " (478, 466): 479,\n",
       " (415, 115): 480,\n",
       " (414, 284): 481,\n",
       " (413, 260): 482,\n",
       " (408, 32): 483,\n",
       " (405, 115): 484,\n",
       " (401, 343): 485,\n",
       " (401, 116): 486,\n",
       " (486, 45): 487,\n",
       " (397, 323): 488,\n",
       " (396, 121): 489,\n",
       " (394, 260): 490,\n",
       " (393, 260): 491,\n",
       " (386, 304): 492,\n",
       " (492, 268): 493,\n",
       " (493, 102): 494,\n",
       " (494, 360): 495,\n",
       " (384, 278): 496,\n",
       " (496, 359): 497,\n",
       " (497, 495): 498,\n",
       " (377, 327): 499,\n",
       " (369, 454): 500,\n",
       " (366, 107): 501,\n",
       " (363, 488): 502,\n",
       " (361, 267): 503,\n",
       " (361, 263): 504,\n",
       " (504, 314): 505,\n",
       " (358, 99): 506,\n",
       " (506, 319): 507,\n",
       " (507, 498): 508,\n",
       " (354, 52): 509,\n",
       " (509, 32): 510,\n",
       " (510, 500): 511}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the learned merge rules from the BPE process\n",
    "# Format: {(token1, token2): new_token_id}\n",
    "# This shows which byte pairs were merged and what new token ID was assigned to each\n",
    "\n",
    "merge_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a2e9e9-4b61-43df-9928-de10fb6f6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode a given text into BPE token IDs using the learned merge rules.\n",
    "\n",
    "def encoder(text, merge_dict): \n",
    "    tokens = list(text.encode(\"utf-8\"))  # Convert input text to UTF-8 byte tokens\n",
    "    i = 0\n",
    "    while i < len(tokens) - 1:\n",
    "        pair = tokens[i], tokens[i + 1]  # Form adjacent pair\n",
    "        if pair in merge_dict:\n",
    "            # If the pair exists in merge rules, merge them into a new token\n",
    "            tokens = merge(tokens, pair, merge_dict[pair])\n",
    "            # Note: Restarting from i=0 after merge would be more robust in some BPE variants\n",
    "        i += 1\n",
    "    return tokens  # Return the encoded token sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3087b6d-bea1-4602-bfc1-9dd0194222d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the input text using the previously learned BPE merge rules\n",
    "encoded_token = encoder(text, merge_dict)\n",
    "\n",
    "# Measure the length of the encoded token sequence\n",
    "# This helps compare with the original token count to evaluate compression\n",
    "len(encoded_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d823ac0-5113-40e8-9e08-eda09dedea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode a BPE token sequence back to its original text form using reverse merge rules.\n",
    "\n",
    "def decoder(tokens, merge_dict):\n",
    "    # Create a reverse mapping: {new_token_id: (original_pair)}\n",
    "    map_merge = {v: k for k, v in merge_dict.items()}\n",
    "\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # Repeat until all merged token IDs are broken down into basic byte tokens (<= 255)\n",
    "    while max(tokens) > 256:\n",
    "        decoded_tokens = []\n",
    "        for token in tokens:\n",
    "            if token in merge_dict.values():\n",
    "                # If the token is a merged token, replace it with its original pair\n",
    "                decoded_tokens.extend(list(map_merge.get(token)))\n",
    "            else:\n",
    "                # Keep unmerged byte-level tokens as is\n",
    "                decoded_tokens.append(token)\n",
    "        tokens = decoded_tokens  # Update tokens after one round of decoding\n",
    "\n",
    "    # Convert final byte-level tokens back to a UTF-8 string\n",
    "    return bytes(decoded_tokens).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04202206-887f-4268-a4b1-41e1d3772c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Virat Kohli (born 5 November 1988)[a] is an Indian international cricketer who plays ODI cricket for the national team and is a former captain in all formats.[3] He is a right-handed batsman and occasional right-arm medium pace bowler. Considered one of the greatest all-format batsmen in the history of cricket, he is called the King, the Chase Master, and the Run Machine for his skills, records and ability to lead his team to victory.[4] Kohli is the highest run-scorer in the Indian Premier League, third in T20I, third in ODI, and third in international cricket.[5] He has the most ODI centuries and second-most centuries in international cricket, with a total of 82 centuries across all international formats of the game.[6] Kohli is also the most successful Test captain of India with back-to-back Test mace wins and most victories in his tenure.[7] He is the only batter to earn 900 rating points in all three formats.[8] Kohli was the captain of the 2008 U19 World Cup winning team and was a crucial member of the teams that won 2011 ODI World Cup, 2013 Champions Trophy, 2024 T20 World Cup, and 2025 Champions Trophy. He plays for Royal Challengers Bengaluru in the Indian Premier League and for Delhi in domestic cricket. In 2013, Kohli was ranked number one in the ODI batting rankings. In 2015, he achieved the same in T20I.[9] In 2018, he was ranked number one in Test, making him the only Indian to hold the number one spot in all three formats. He is the first player to score 20,000 runs in a decade. He was the Cricketer of the Decade for 2011 to 2020.[10] Kohli has won ten ICC Awards, making him the most awarded player in international cricket history. He won the ODI Player of the Year award four times in 2012, 2017, 2018, and 2023. He won the Cricketer of the Year award, on two occasions, in 2017 and 2018. In 2018, he became the first player to win all three major awards including Cricketer of the Year, ODI Player of the Year and Test Player of the Year in the same year. He was honored with the Spirit of Cricket Award in 2019 and given the Cricketer of the Decade and ODI Cricketer of the Decade in 2020. Kohli was named the Wisden Leading Cricketer in the World for three consecutive years. Kohli has the most Player of the Series and second most Player of the Match awards to his name in all three formats combined. He was honoured with the Arjuna Award in 2013, the Padma Shri in 2017, and India's highest sporting honour, the Khel Ratna Award, in 2018. Time included him on its 100 most influential people in the world list in 2018.After winning the 2024 T20 World Cup and winning the Player of the Match award in the final, Kohli announced his retirement from T20Is.[11] On 12 May 2025, aged 36, he announced his retirement from the Test format.[12] He is married to actress Anushka Sharma, and they have two children.[13]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the previously encoded BPE token sequence back to the original text\n",
    "# This should return the exact input string (e.g., \"Virat Kohli\") if encoding and decoding worked correctly\n",
    "\n",
    "decoder(encoded_token, merge_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef1f290f-44b3-4151-af5b-39b32afd0120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Virat Kohli (born 5 November 1988) - ADDED THESE EMOJI ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the input text (including emojis and punctuation) using BPE\n",
    "# Then immediately decode it back to verify correctness\n",
    "\n",
    "decoder(\n",
    "    encoder(\"Virat Kohli (born 5 November 1988) - ADDED THESE EMOJI ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚\", merge_dict),\n",
    "    merge_dict\n",
    ")\n",
    "\n",
    "# This should return the original string exactly if all byte merges and reversals worked correctly\n",
    "# UTF-8 ensures emojis and special characters are preserved during encoding and decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "52f64c59-3614-4c9b-ae4f-e25be34aaed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPE:\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.merge_dict = {}        # Stores merge rules: {(token1, token2): new_token_id}\n",
    "        self.tokens = None          # Final token sequence after training\n",
    "        self.text = None            # Optional reference to original text\n",
    "        self.vocab_size = None      # Total size of vocabulary after training\n",
    "        self.encoded_tokens = None  # Tokens generated after encoding input text\n",
    "        self.decoded_tokens = None  # Decoded text string from token sequence\n",
    "        self.special_tokens = None  # Any manually added special tokens (e.g., <PAD>, <BOS>)\n",
    "        self.vocab = {}             # Maps token_id â†’ byte sequence\n",
    "\n",
    "    def add_special_tokens(self, special_tokens):\n",
    "        if self.special_tokens is None:\n",
    "            self.special_tokens = {}\n",
    "\n",
    "        reverse_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        current_max_id = max(self.vocab.keys(), default=255)\n",
    "\n",
    "        for token in special_tokens:\n",
    "            token_bytes = token.encode(\"utf-8\")\n",
    "\n",
    "            # If the byte version already exists in vocab, re-use the same ID\n",
    "            if token_bytes in reverse_vocab:\n",
    "                token_id = reverse_vocab[token_bytes]\n",
    "            else:\n",
    "                # Else assign a new ID\n",
    "                current_max_id += 1\n",
    "                token_id = current_max_id\n",
    "                self.vocab[token_id] = token_bytes\n",
    "\n",
    "            # Track in special_tokens (ensures idempotency)\n",
    "            self.special_tokens[token] = token_id\n",
    "\n",
    "\n",
    "    \n",
    "    def get_token_id(self, token_str):\n",
    "        if self.special_tokens and token_str in self.special_tokens:\n",
    "            return self.special_tokens[token_str]\n",
    "        return None\n",
    "\n",
    "    def get_vocab(self):\n",
    "        # Build the full vocabulary from merge_dict and initial byte tokens (0-255)\n",
    "        vocab = {i: bytes([i]) for i in range(256)}\n",
    "        for (p0, p1), x in self.merge_dict.items():\n",
    "            vocab[x] = vocab[p0] + vocab[p1]\n",
    "        return vocab\n",
    "\n",
    "    def get_stats(self, tokens=None): \n",
    "        # Count frequency of all adjacent token pairs in the sequence\n",
    "        freq = {}\n",
    "        for i in range(len(tokens) - 1): \n",
    "            pair = tokens[i], tokens[i + 1]\n",
    "            freq[pair] = freq.get(pair, 0) + 1\n",
    "        return freq\n",
    "\n",
    "    def merge(self, tokens=None, pair=None, idx=None): \n",
    "        # Merge all instances of the target pair into a single token ID (idx)\n",
    "        new_tokens = []\n",
    "        i = 0\n",
    "        while i < len(tokens): \n",
    "            if i < len(tokens) - 1 and (tokens[i], tokens[i + 1]) == pair:\n",
    "                new_tokens.append(idx)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_tokens.append(tokens[i])\n",
    "                i += 1\n",
    "        return new_tokens\n",
    "\n",
    "    def fit(self, text=None, vocab_size=384):\n",
    "        # Train the BPE tokenizer: learn merge rules and generate token sequence\n",
    "        if vocab_size > 256:\n",
    "            self.vocab_size = vocab_size\n",
    "        else:\n",
    "            self.vocab_size = None  # invalid size\n",
    "\n",
    "        original_tokens = list(text.encode(\"utf-8\"))  # convert text to byte-level tokens\n",
    "        tokens = list(original_tokens)\n",
    "\n",
    "        if vocab_size <= 256 or vocab_size > len(tokens):\n",
    "            return None  # skip training if invalid\n",
    "\n",
    "        idx = 256  # start assigning new token IDs after byte range\n",
    "        n_merges = vocab_size - 256\n",
    "\n",
    "        for _ in range(n_merges):\n",
    "            vocab = self.get_stats(tokens)  # get pair frequencies\n",
    "            freq_pair = max(sorted([(v, k) for k, v in vocab.items()], reverse=True))[1]\n",
    "            self.merge_dict[freq_pair] = idx\n",
    "            tokens = self.merge(tokens, freq_pair, idx)\n",
    "            idx += 1\n",
    "\n",
    "        self.vocab = self.get_vocab()  # build vocab from merges\n",
    "        self.tokens = tokens  # store final token sequence\n",
    "\n",
    "    def encode(self, text=None):\n",
    "        # Convert text to token sequence using the trained merge_dict\n",
    "        if text:\n",
    "            tokens = list(text.encode(\"utf-8\"))\n",
    "        else:\n",
    "            tokens = self.tokens\n",
    "\n",
    "        try:\n",
    "            merge_dict = self.merge_dict\n",
    "            i = 0\n",
    "            while i < len(tokens) - 1:\n",
    "                pair = tokens[i], tokens[i + 1]\n",
    "                if pair in merge_dict:\n",
    "                    tokens = self.merge(tokens, pair, merge_dict[pair])\n",
    "                i += 1\n",
    "            self.encoded_tokens = tokens\n",
    "            return self.encoded_tokens\n",
    "        except: \n",
    "            return []\n",
    "\n",
    "    def decode_old(self, tokens=None):\n",
    "        # Decode by recursively splitting merged tokens using reverse merge_dict\n",
    "        if not tokens:\n",
    "            tokens = self.encoded_tokens\n",
    "\n",
    "        merge_dict = self.merge_dict\n",
    "        map_merge = {v: k for k, v in merge_dict.items()}\n",
    "        decoded_tokens = []\n",
    "\n",
    "        while max(tokens) > 255:\n",
    "            decoded_tokens = []\n",
    "            for token in tokens:\n",
    "                if token in merge_dict.values():\n",
    "                    decoded_tokens.extend(list(map_merge.get(token)))\n",
    "                else:\n",
    "                    decoded_tokens.append(token)\n",
    "            tokens = decoded_tokens\n",
    "\n",
    "        self.decoded_tokens = bytes(decoded_tokens).decode('utf-8')\n",
    "        return self.decoded_tokens\n",
    "\n",
    "    def decode(self, tokens=None):\n",
    "        # Decode using precomputed vocab (faster than decode_old)\n",
    "        if not tokens:\n",
    "            tokens = self.encoded_tokens\n",
    "        try:\n",
    "            self.decoded_tokens = b\"\".join(self.vocab.get(x) for x in tokens).decode(\"utf-8\", errors='replace')\n",
    "        except: \n",
    "            self.decoded_tokens = \"\".join(self.vocab.get(str(x)) for x in tokens)\n",
    "\n",
    "        return self.decoded_tokens\n",
    "\n",
    "    def save_json(self, path=\"bpe_tokenizer.json\"):\n",
    "        \"\"\"Save tokenizer merge rules and vocab size as a JSON file\"\"\"\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"merge_dict\": {str(k): v for k, v in self.merge_dict.items()},\n",
    "                \"vocab\": {str(k): v.decode(\"utf-8\", errors=\"replace\") for k, v in self.get_vocab().items()},\n",
    "                \"vocab_size\": len(self.vocab)\n",
    "            }, f)\n",
    "\n",
    "    def save_pickle(self, path=\"bpe_tokenizer.pkl\"):\n",
    "        # Save merge rules and vocab in binary form for reloading\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"merge_dict\": self.merge_dict,\n",
    "                \"vocab\": self.vocab,\n",
    "                \"vocab_size\": self.vocab_size\n",
    "            }, f)\n",
    "\n",
    "    def load_json(self, path=\"bpe_tokenizer.json\"):\n",
    "        \"\"\"Load tokenizer merge rules and vocab size from a JSON file\"\"\"\n",
    "        with open(path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            self.vocab_size = data[\"vocab_size\"]\n",
    "            self.merge_dict = data[\"merge_dict\"]\n",
    "            self.vocab = data[\"vocab\"]\n",
    "\n",
    "    def load_pickle(self, path=\"bpe_tokenizer.pkl\"):\n",
    "        # Load BPE model from pickle file (faster than JSON)\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            self.merge_dict = data[\"merge_dict\"]\n",
    "            self.vocab = data[\"vocab\"]\n",
    "            self.vocab_size = data[\"vocab_size\"]\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        # Return the current size of the vocabulary\n",
    "        return len(self.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4949944e-8552-4665-8a18-71b1ac6948d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTING THAT TEXT AGAIN FOR REFERENCE\n",
    "text = \"Virat Kohli ðŸ˜…ðŸ˜‚ðŸâš¡ (born 5 November 1988)[a] is an Indian international cricketer  who plays ODI cricket for the national team and is a former captain in all formats.[3] He is a right-handed batsman and occasional right-arm medium pace bowler. Considered one of the greatest all-format batsmen in the history of cricket, he is called the King, the Chase Master, and the Run Machine for his skills, records and ability to lead his team to victory.[4] Kohli is the highest run-scorer in the Indian Premier League, third in T20I, third in ODI, and third in international cricket.[5] He has the most ODI centuries and second-most centuries in international cricket, with a total of 82 centuries across all international formats of the game.[6] Kohli is also the most successful Test captain of India with back-to-back Test mace wins and most victories in his tenure.[7] He is the only batter to earn 900 rating points in all three formats.[8] Kohli was the captain of the 2008 U19 World Cup winning team and was a crucial member of the teams that won 2011 ODI World Cup, 2013 Champions Trophy, 2024 T20 World Cup, and 2025 Champions Trophy. He plays for Royal Challengers Bengaluru in the Indian Premier League and for Delhi in domestic cricket. In 2013, Kohli was ranked number one in the ODI batting rankings. In 2015, he achieved the same in T20I.[9] In 2018, he was ranked number one in Test, making him the only Indian to hold the number one spot in all three formats. He is the first player to score 20,000 runs in a decade. He was the Cricketer of the Decade for 2011 to 2020.[10] Kohli has won ten ICC Awards, making him the most awarded player in international cricket history. He won the ODI Player of the Year award four times in 2012, 2017, 2018, and 2023. He won the Cricketer of the Year award, on two occasions, in 2017 and 2018. In 2018, he became the first player to win all three major awards including Cricketer of the Year, ODI Player of the Year and Test Player of the Year in the same year. He was honored with the Spirit of Cricket Award in 2019 and given the Cricketer of the Decade and ODI Cricketer of the Decade in 2020. Kohli was named the Wisden Leading Cricketer in the World for three consecutive years. Kohli has the most Player of the Series and second most Player of the Match awards to his name in all three formats combined. He was honoured with the Arjuna Award in 2013, the Padma Shri in 2017, and India's highest sporting honour, the Khel Ratna Award, in 2018. Time included him on its 100 most influential people in the world list in 2018.After winning the 2024 T20 World Cup and winning the Player of the Match award in the final, Kohli announced his retirement from T20Is.[11] On 12 May 2025, aged 36, he announced his retirement from the Test format.[12] He is married to actress Anushka Sharma, and they have two children.[13]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6103155f-f747-4c40-b83c-725dec92e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the BPE class\n",
    "bpe = BPE()\n",
    "\n",
    "# Train the BPE tokenizer on the given input `text` with a target vocabulary size of 260\n",
    "# This will learn 4 merge rules (260 - 256) and update `bpe.merge_dict`, `bpe.vocab`, and `bpe.tokens`\n",
    "bpe.fit(text=text, vocab_size=260)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a6cd73f9-f216-4c60-87f2-2752bb9ed1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Virat Kohli ðŸ˜…ðŸ˜‚ðŸâš¡ (born 5 November 1988)[a] is an I'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the first 50 characters of the input text using the trained BPE model\n",
    "# This will return a list of token IDs based on learned merge rules\n",
    "encoded = bpe.encode(text[:50])\n",
    "\n",
    "# Decode the encoded tokens back to a UTF-8 string\n",
    "# This should reconstruct the original 50 characters accurately\n",
    "bpe.decode(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d92a9259-84c2-457e-9f9a-3bd56bdee342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THESE LINES ARE DECODED WITH PICKLE: ðŸ˜…ðŸ˜‚ðŸâš¡'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the current BPE model (merge_dict, vocab, vocab_size) to a file named 'bpe_tokenizer.pkl'\n",
    "# This allows the model to be reused later without retraining\n",
    "bpe.save_pickle()\n",
    "\n",
    "# Load the saved BPE model back into the current instance\n",
    "# Useful for restoring the tokenizer in a new session or script\n",
    "bpe.load_pickle()\n",
    "\n",
    "# Decode the previously encoded token sequence using the reloaded model\n",
    "# This should return the original text used to produce `encoded`\n",
    "bpe.decode(encoded)\n",
    "\n",
    "# Encode a new string containing emojis and uppercase letters using the reloaded model\n",
    "# Then decode it back to verify that the model works as expected after loading from pickle\n",
    "bpe.decode(bpe.encode(\"THESE LINES ARE DECODED WITH PICKLE: ðŸ˜…ðŸ˜‚ðŸâš¡\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fb0f16bd-d966-4258-9e11-44fefcaec30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THESE LINES MAY FAIL TO DECODE EVEN THOUGH THEY ARE IN TRAINING : ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the BPE tokenizer to a human-readable JSON file (default: 'bpe_tokenizer.json')\n",
    "# This stores the merge_dict and vocab in a structured, text-based format\n",
    "bpe.save_json()\n",
    "\n",
    "# Load the tokenizer from the saved JSON file\n",
    "# WARNING: The merge_dict keys were stored as strings, so without parsing them back into tuples,\n",
    "#          the decoder may not correctly match and decode merged tokens\n",
    "bpe.load_json()\n",
    "\n",
    "# Decode the previously encoded tokens\n",
    "# This may succeed only if the stringified merge_dict was correctly parsed back into tuple format\n",
    "bpe.decode(encoded)\n",
    "\n",
    "# FAIL EXAMPLE:\n",
    "# Attempt to encode and decode a string that was present during training\n",
    "# It may fail or return incorrect results because the merge_dict keys are not tuples after JSON load\n",
    "bpe.decode(bpe.encode(\"THESE LINES MAY FAIL TO DECODE EVEN THOUGH THEY ARE IN TRAINING : ðŸ˜…ðŸ˜‚ðŸâš¡\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c833bf3f-e479-40f3-9a68-0fdb683ba3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained BPE model from the pickle file\n",
    "# This restores merge_dict, vocab, and vocab_size\n",
    "bpe.load_pickle()\n",
    "\n",
    "# Determine the next available token ID after the current vocab\n",
    "# Special tokens should not conflict with existing token IDs\n",
    "start_id = bpe.get_vocab_size()\n",
    "\n",
    "# Define special tokens with unique token IDs beyond the current vocab\n",
    "# These can be used during training or inference in downstream NLP models\n",
    "specials = {\n",
    "    \"<PAD>\": start_id,       # Padding token\n",
    "    \"<UNK>\": start_id + 1,   # Unknown token\n",
    "    \"<BOS>\": start_id + 2,   # Beginning of sequence\n",
    "    \"<EOS>\": start_id + 3,   # End of sequence\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the defined special tokens to the BPE vocabulary\n",
    "# Each token is encoded into its UTF-8 byte representation and stored in the vocab dictionary\n",
    "# This allows the encoder/decoder to recognize and utilize these tokens if explicitly added\n",
    "\n",
    "bpe.add_special_tokens(special_tokens=specials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the updated vocabulary size after adding special tokens\n",
    "# This should now include the original BPE tokens + the number of special tokens added\n",
    "\n",
    "bpe.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.get_token_id(\"<PAD>\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = bpe.get_vocab_size()\n",
    "specials = {\n",
    "    \"<PAD>\": start_id,\n",
    "    \"<UNK>\": start_id + 1,\n",
    "    \"<BOS>\": start_id + 2,\n",
    "    \"<EOS>\": start_id + 3,\n",
    "}\n",
    "\n",
    "bpe.add_special_tokens(special_tokens=specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.get_token_id(\"<PAD>\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bpe.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: b'\\x00',\n",
       " 1: b'\\x01',\n",
       " 2: b'\\x02',\n",
       " 3: b'\\x03',\n",
       " 4: b'\\x04',\n",
       " 5: b'\\x05',\n",
       " 6: b'\\x06',\n",
       " 7: b'\\x07',\n",
       " 8: b'\\x08',\n",
       " 9: b'\\t',\n",
       " 10: b'\\n',\n",
       " 11: b'\\x0b',\n",
       " 12: b'\\x0c',\n",
       " 13: b'\\r',\n",
       " 14: b'\\x0e',\n",
       " 15: b'\\x0f',\n",
       " 16: b'\\x10',\n",
       " 17: b'\\x11',\n",
       " 18: b'\\x12',\n",
       " 19: b'\\x13',\n",
       " 20: b'\\x14',\n",
       " 21: b'\\x15',\n",
       " 22: b'\\x16',\n",
       " 23: b'\\x17',\n",
       " 24: b'\\x18',\n",
       " 25: b'\\x19',\n",
       " 26: b'\\x1a',\n",
       " 27: b'\\x1b',\n",
       " 28: b'\\x1c',\n",
       " 29: b'\\x1d',\n",
       " 30: b'\\x1e',\n",
       " 31: b'\\x1f',\n",
       " 32: b' ',\n",
       " 33: b'!',\n",
       " 34: b'\"',\n",
       " 35: b'#',\n",
       " 36: b'$',\n",
       " 37: b'%',\n",
       " 38: b'&',\n",
       " 39: b\"'\",\n",
       " 40: b'(',\n",
       " 41: b')',\n",
       " 42: b'*',\n",
       " 43: b'+',\n",
       " 44: b',',\n",
       " 45: b'-',\n",
       " 46: b'.',\n",
       " 47: b'/',\n",
       " 48: b'0',\n",
       " 49: b'1',\n",
       " 50: b'2',\n",
       " 51: b'3',\n",
       " 52: b'4',\n",
       " 53: b'5',\n",
       " 54: b'6',\n",
       " 55: b'7',\n",
       " 56: b'8',\n",
       " 57: b'9',\n",
       " 58: b':',\n",
       " 59: b';',\n",
       " 60: b'<',\n",
       " 61: b'=',\n",
       " 62: b'>',\n",
       " 63: b'?',\n",
       " 64: b'@',\n",
       " 65: b'A',\n",
       " 66: b'B',\n",
       " 67: b'C',\n",
       " 68: b'D',\n",
       " 69: b'E',\n",
       " 70: b'F',\n",
       " 71: b'G',\n",
       " 72: b'H',\n",
       " 73: b'I',\n",
       " 74: b'J',\n",
       " 75: b'K',\n",
       " 76: b'L',\n",
       " 77: b'M',\n",
       " 78: b'N',\n",
       " 79: b'O',\n",
       " 80: b'P',\n",
       " 81: b'Q',\n",
       " 82: b'R',\n",
       " 83: b'S',\n",
       " 84: b'T',\n",
       " 85: b'U',\n",
       " 86: b'V',\n",
       " 87: b'W',\n",
       " 88: b'X',\n",
       " 89: b'Y',\n",
       " 90: b'Z',\n",
       " 91: b'[',\n",
       " 92: b'\\\\',\n",
       " 93: b']',\n",
       " 94: b'^',\n",
       " 95: b'_',\n",
       " 96: b'`',\n",
       " 97: b'a',\n",
       " 98: b'b',\n",
       " 99: b'c',\n",
       " 100: b'd',\n",
       " 101: b'e',\n",
       " 102: b'f',\n",
       " 103: b'g',\n",
       " 104: b'h',\n",
       " 105: b'i',\n",
       " 106: b'j',\n",
       " 107: b'k',\n",
       " 108: b'l',\n",
       " 109: b'm',\n",
       " 110: b'n',\n",
       " 111: b'o',\n",
       " 112: b'p',\n",
       " 113: b'q',\n",
       " 114: b'r',\n",
       " 115: b's',\n",
       " 116: b't',\n",
       " 117: b'u',\n",
       " 118: b'v',\n",
       " 119: b'w',\n",
       " 120: b'x',\n",
       " 121: b'y',\n",
       " 122: b'z',\n",
       " 123: b'{',\n",
       " 124: b'|',\n",
       " 125: b'}',\n",
       " 126: b'~',\n",
       " 127: b'\\x7f',\n",
       " 128: b'\\x80',\n",
       " 129: b'\\x81',\n",
       " 130: b'\\x82',\n",
       " 131: b'\\x83',\n",
       " 132: b'\\x84',\n",
       " 133: b'\\x85',\n",
       " 134: b'\\x86',\n",
       " 135: b'\\x87',\n",
       " 136: b'\\x88',\n",
       " 137: b'\\x89',\n",
       " 138: b'\\x8a',\n",
       " 139: b'\\x8b',\n",
       " 140: b'\\x8c',\n",
       " 141: b'\\x8d',\n",
       " 142: b'\\x8e',\n",
       " 143: b'\\x8f',\n",
       " 144: b'\\x90',\n",
       " 145: b'\\x91',\n",
       " 146: b'\\x92',\n",
       " 147: b'\\x93',\n",
       " 148: b'\\x94',\n",
       " 149: b'\\x95',\n",
       " 150: b'\\x96',\n",
       " 151: b'\\x97',\n",
       " 152: b'\\x98',\n",
       " 153: b'\\x99',\n",
       " 154: b'\\x9a',\n",
       " 155: b'\\x9b',\n",
       " 156: b'\\x9c',\n",
       " 157: b'\\x9d',\n",
       " 158: b'\\x9e',\n",
       " 159: b'\\x9f',\n",
       " 160: b'\\xa0',\n",
       " 161: b'\\xa1',\n",
       " 162: b'\\xa2',\n",
       " 163: b'\\xa3',\n",
       " 164: b'\\xa4',\n",
       " 165: b'\\xa5',\n",
       " 166: b'\\xa6',\n",
       " 167: b'\\xa7',\n",
       " 168: b'\\xa8',\n",
       " 169: b'\\xa9',\n",
       " 170: b'\\xaa',\n",
       " 171: b'\\xab',\n",
       " 172: b'\\xac',\n",
       " 173: b'\\xad',\n",
       " 174: b'\\xae',\n",
       " 175: b'\\xaf',\n",
       " 176: b'\\xb0',\n",
       " 177: b'\\xb1',\n",
       " 178: b'\\xb2',\n",
       " 179: b'\\xb3',\n",
       " 180: b'\\xb4',\n",
       " 181: b'\\xb5',\n",
       " 182: b'\\xb6',\n",
       " 183: b'\\xb7',\n",
       " 184: b'\\xb8',\n",
       " 185: b'\\xb9',\n",
       " 186: b'\\xba',\n",
       " 187: b'\\xbb',\n",
       " 188: b'\\xbc',\n",
       " 189: b'\\xbd',\n",
       " 190: b'\\xbe',\n",
       " 191: b'\\xbf',\n",
       " 192: b'\\xc0',\n",
       " 193: b'\\xc1',\n",
       " 194: b'\\xc2',\n",
       " 195: b'\\xc3',\n",
       " 196: b'\\xc4',\n",
       " 197: b'\\xc5',\n",
       " 198: b'\\xc6',\n",
       " 199: b'\\xc7',\n",
       " 200: b'\\xc8',\n",
       " 201: b'\\xc9',\n",
       " 202: b'\\xca',\n",
       " 203: b'\\xcb',\n",
       " 204: b'\\xcc',\n",
       " 205: b'\\xcd',\n",
       " 206: b'\\xce',\n",
       " 207: b'\\xcf',\n",
       " 208: b'\\xd0',\n",
       " 209: b'\\xd1',\n",
       " 210: b'\\xd2',\n",
       " 211: b'\\xd3',\n",
       " 212: b'\\xd4',\n",
       " 213: b'\\xd5',\n",
       " 214: b'\\xd6',\n",
       " 215: b'\\xd7',\n",
       " 216: b'\\xd8',\n",
       " 217: b'\\xd9',\n",
       " 218: b'\\xda',\n",
       " 219: b'\\xdb',\n",
       " 220: b'\\xdc',\n",
       " 221: b'\\xdd',\n",
       " 222: b'\\xde',\n",
       " 223: b'\\xdf',\n",
       " 224: b'\\xe0',\n",
       " 225: b'\\xe1',\n",
       " 226: b'\\xe2',\n",
       " 227: b'\\xe3',\n",
       " 228: b'\\xe4',\n",
       " 229: b'\\xe5',\n",
       " 230: b'\\xe6',\n",
       " 231: b'\\xe7',\n",
       " 232: b'\\xe8',\n",
       " 233: b'\\xe9',\n",
       " 234: b'\\xea',\n",
       " 235: b'\\xeb',\n",
       " 236: b'\\xec',\n",
       " 237: b'\\xed',\n",
       " 238: b'\\xee',\n",
       " 239: b'\\xef',\n",
       " 240: b'\\xf0',\n",
       " 241: b'\\xf1',\n",
       " 242: b'\\xf2',\n",
       " 243: b'\\xf3',\n",
       " 244: b'\\xf4',\n",
       " 245: b'\\xf5',\n",
       " 246: b'\\xf6',\n",
       " 247: b'\\xf7',\n",
       " 248: b'\\xf8',\n",
       " 249: b'\\xf9',\n",
       " 250: b'\\xfa',\n",
       " 251: b'\\xfb',\n",
       " 252: b'\\xfc',\n",
       " 253: b'\\xfd',\n",
       " 254: b'\\xfe',\n",
       " 255: b'\\xff',\n",
       " 256: b'e ',\n",
       " 257: b' t',\n",
       " 258: b'in',\n",
       " 259: b' th',\n",
       " 260: b'<PAD>',\n",
       " 261: b'<UNK>',\n",
       " 262: b'<BOS>',\n",
       " 263: b'<EOS>'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
